"""
é¢˜ç›®ç”ŸæˆLangGraphå·¥ä½œæµ
"""
import logging
from typing import Dict, Any
from langgraph.graph import StateGraph, END

from schemas import GraphState
from nodes import (
    DocumentProcessorNode,
    DocumentAnalyzerNode,
    MultipleChoiceGeneratorNode,
    FillInTheBlankGeneratorNode,
    MatchingGeneratorNode,
    OutputFormatterNode
)

logger = logging.getLogger(__name__)


class QuestionGeneratorGraph:
    """é¢˜ç›®ç”Ÿæˆå·¥ä½œæµå›¾"""
    
    def __init__(self):
        self.graph = None
        self._initialize_nodes()
        self._build_graph()
    
    def _initialize_nodes(self):
        """åˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹"""
        self.document_processor = DocumentProcessorNode()
        self.document_analyzer = DocumentAnalyzerNode()
        self.mc_generator = MultipleChoiceGeneratorNode()
        self.fib_generator = FillInTheBlankGeneratorNode()
        self.matching_generator = MatchingGeneratorNode()
        self.output_formatter = OutputFormatterNode()
    
    def _build_graph(self):
        """æ„å»ºLangGraphå·¥ä½œæµ"""
        
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(GraphState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("document_processor", self._process_document)
        workflow.add_node("document_analyzer", self._analyze_document)
        workflow.add_node("generate_multiple_choice", self._generate_multiple_choice)
        workflow.add_node("generate_fill_blank", self._generate_fill_blank)
        workflow.add_node("generate_matching", self._generate_matching)
        workflow.add_node("format_output", self._format_output)
        workflow.add_node("error_handler", self._handle_error)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("document_processor")
        
        # æ·»åŠ æ¡ä»¶è¾¹
        workflow.add_conditional_edges(
            "document_processor",
            self._route_after_processing,
            {
                "analyze": "document_analyzer",
                "error": "error_handler"
            }
        )
        
        workflow.add_conditional_edges(
            "document_analyzer", 
            self._route_after_analysis,
            {
                "generate_questions": "generate_multiple_choice",
                "error": "error_handler"
            }
        )
        
        # é¢˜ç›®ç”ŸæˆèŠ‚ç‚¹ä¹‹é—´çš„é¡ºåºè¿æ¥
        workflow.add_edge("generate_multiple_choice", "generate_fill_blank")
        workflow.add_edge("generate_fill_blank", "generate_matching")
        workflow.add_edge("generate_matching", "format_output")
        
        # è¾“å‡ºèŠ‚ç‚¹åˆ°ç»“æŸ
        workflow.add_conditional_edges(
            "format_output",
            self._route_after_formatting,
            {
                "end": END,
                "error": "error_handler"
            }
        )
        
        # é”™è¯¯å¤„ç†èŠ‚ç‚¹åˆ°ç»“æŸ
        workflow.add_edge("error_handler", END)
        
        # ç¼–è¯‘å›¾
        self.graph = workflow.compile()
    
    # èŠ‚ç‚¹å¤„ç†å‡½æ•°
    async def _process_document(self, state: GraphState) -> GraphState:
        """æ–‡æ¡£å¤„ç†èŠ‚ç‚¹"""
        logger.info("æ‰§è¡Œæ–‡æ¡£å¤„ç†èŠ‚ç‚¹...")
        return await self.document_processor.process(state)
    
    async def _analyze_document(self, state: GraphState) -> GraphState:
        """æ–‡æ¡£åˆ†æèŠ‚ç‚¹"""
        logger.info("æ‰§è¡Œæ–‡æ¡£åˆ†æèŠ‚ç‚¹...")
        return await self.document_analyzer.process(state)
    
    async def _generate_multiple_choice(self, state: GraphState) -> GraphState:
        """é€‰æ‹©é¢˜ç”ŸæˆèŠ‚ç‚¹"""
        logger.info("æ‰§è¡Œé€‰æ‹©é¢˜ç”ŸæˆèŠ‚ç‚¹...")
        return await self.mc_generator.process(state)
    
    async def _generate_fill_blank(self, state: GraphState) -> GraphState:
        """å¡«ç©ºé¢˜ç”ŸæˆèŠ‚ç‚¹"""
        logger.info("æ‰§è¡Œå¡«ç©ºé¢˜ç”ŸæˆèŠ‚ç‚¹...")
        return await self.fib_generator.process(state)
    
    async def _generate_matching(self, state: GraphState) -> GraphState:
        """è¿çº¿é¢˜ç”ŸæˆèŠ‚ç‚¹"""
        logger.info("æ‰§è¡Œè¿çº¿é¢˜ç”ŸæˆèŠ‚ç‚¹...")
        return await self.matching_generator.process(state)
    
    async def _format_output(self, state: GraphState) -> GraphState:
        """è¾“å‡ºæ ¼å¼åŒ–èŠ‚ç‚¹"""
        logger.info("æ‰§è¡Œè¾“å‡ºæ ¼å¼åŒ–èŠ‚ç‚¹...")
        return await self.output_formatter.process(state)
    
    async def _handle_error(self, state: GraphState) -> GraphState:
        """é”™è¯¯å¤„ç†èŠ‚ç‚¹"""
        logger.error(f"å·¥ä½œæµå‡ºç°é”™è¯¯: {state.error_message}")
        state.current_step = "error_handled"
        return state
    
    # è·¯ç”±æ¡ä»¶å‡½æ•°
    def _route_after_processing(self, state: GraphState) -> str:
        """æ–‡æ¡£å¤„ç†åçš„è·¯ç”±"""
        if state.current_step == "error":
            return "error"
        elif state.current_step == "document_processed":
            return "analyze"
        else:
            return "error"
    
    def _route_after_analysis(self, state: GraphState) -> str:
        """æ–‡æ¡£åˆ†æåçš„è·¯ç”±"""
        if state.current_step == "error":
            return "error"
        elif state.current_step == "document_analyzed":
            return "generate_questions"
        else:
            return "error"
    
    def _route_after_formatting(self, state: GraphState) -> str:
        """è¾“å‡ºæ ¼å¼åŒ–åçš„è·¯ç”±"""
        if state.current_step == "error":
            return "error"
        elif state.current_step == "completed":
            return "end"
        else:
            return "error"
    
    async def run(self, initial_state: GraphState) -> GraphState:
        """
        è¿è¡Œé¢˜ç›®ç”Ÿæˆå·¥ä½œæµ
        
        Args:
            initial_state: åˆå§‹çŠ¶æ€ï¼ŒåŒ…å«æ–‡æ¡£ä¿¡æ¯
            
        Returns:
            æœ€ç»ˆçŠ¶æ€ï¼ŒåŒ…å«ç”Ÿæˆçš„é¢˜ç›®
        """
        try:
            logger.info("å¼€å§‹è¿è¡Œé¢˜ç›®ç”Ÿæˆå·¥ä½œæµ...")
            
            # è¿è¡Œå›¾ - å…¼å®¹ä¸åŒç‰ˆæœ¬çš„API
            try:
                # æ–°ç‰ˆæœ¬API
                result = await self.graph.ainvoke(initial_state)
                # ç¡®ä¿è¿”å›çš„æ˜¯GraphStateå¯¹è±¡
                if isinstance(result, dict):
                    final_state = GraphState(**result)
                else:
                    final_state = result
            except AttributeError:
                # å¦‚æœæ²¡æœ‰ainvokeæ–¹æ³•ï¼Œå°è¯•å…¶ä»–æ–¹å¼
                try:
                    # ä¸€äº›ç‰ˆæœ¬ä½¿ç”¨invoke
                    result = self.graph.invoke(initial_state)
                    if isinstance(result, dict):
                        final_state = GraphState(**result)
                    else:
                        final_state = result
                except AttributeError:
                    # ä½¿ç”¨æµå¼å¤„ç†
                    final_state = initial_state
                    async for state in self.graph.astream(initial_state):
                        if isinstance(state, dict):
                            final_state = GraphState(**state)
                        else:
                            final_state = state
            
            if final_state.current_step == "completed":
                pass  # æˆåŠŸå®Œæˆï¼Œé™é»˜å¤„ç†
            elif final_state.current_step in ["error", "error_handled"]:
                logger.error(f"é¢˜ç›®ç”Ÿæˆå·¥ä½œæµå¤±è´¥: {final_state.error_message}")
            else:
                pass  # æœªçŸ¥çŠ¶æ€ï¼Œé™é»˜å¤„ç†
            
            return final_state
            
        except Exception as e:
            logger.error(f"å·¥ä½œæµè¿è¡Œå¼‚å¸¸: {e}")
            initial_state.error_message = str(e)
            initial_state.current_step = "error"
            return initial_state
    
    def get_graph_visualization(self) -> str:
        """
        è·å–å›¾çš„å¯è§†åŒ–è¡¨ç¤º
        
        Returns:
            å›¾çš„Mermaidæ ¼å¼å­—ç¬¦ä¸²
        """
        mermaid_graph = """
graph TD
    A[Document Processor] --> B{Processing OK?}
    B -->|Yes| C[Document Analyzer]
    B -->|No| H[Error Handler]
    
    C --> D{Analysis OK?}
    D -->|Yes| E[Generate Multiple Choice]
    D -->|No| H
    
    E --> F[Generate Fill-in-the-Blank]
    F --> G[Generate Matching]
    G --> I[Format Output]
    
    I --> J{Formatting OK?}
    J -->|Yes| K[End]
    J -->|No| H
    
    H --> K
    
    style A fill:#e1f5fe
    style C fill:#f3e5f5
    style E fill:#fff3e0
    style F fill:#fff3e0
    style G fill:#fff3e0
    style I fill:#e8f5e8
    style H fill:#ffebee
    style K fill:#f1f8e9
"""
        return mermaid_graph
    
    def get_node_status(self, state: GraphState) -> Dict[str, str]:
        """
        è·å–å„èŠ‚ç‚¹çŠ¶æ€
        
        Args:
            state: å½“å‰çŠ¶æ€
            
        Returns:
            èŠ‚ç‚¹çŠ¶æ€å­—å…¸
        """
        status = {
            "document_processor": "pending",
            "document_analyzer": "pending", 
            "generate_multiple_choice": "pending",
            "generate_fill_blank": "pending",
            "generate_matching": "pending",
            "format_output": "pending"
        }
        
        current_step = state.current_step
        
        if current_step in ["document_processed", "document_analyzed", "completed"]:
            status["document_processor"] = "completed"
        
        if current_step in ["document_analyzed", "completed"]:
            status["document_analyzer"] = "completed"
        
        if state.question_set:
            if state.question_set.multiple_choice:
                status["generate_multiple_choice"] = "completed"
            if state.question_set.fill_in_the_blank:
                status["generate_fill_blank"] = "completed"
            if state.question_set.matching:
                status["generate_matching"] = "completed"
        
        if current_step == "completed":
            status["format_output"] = "completed"
        
        if current_step in ["error", "error_handled"]:
            # å°†æ‰€æœ‰æœªå®Œæˆçš„èŠ‚ç‚¹æ ‡è®°ä¸ºé”™è¯¯
            for node, node_status in status.items():
                if node_status == "pending":
                    status[node] = "error"
        
        return status
    
    def save_graph_visualization(self, output_dir: str = ".") -> Dict[str, str]:
        """
        ä¿å­˜å›¾ç»“æ„çš„å¯è§†åŒ–æ–‡ä»¶
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        import os
        from datetime import datetime
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        # timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        files_saved = {}
        
        try:
            # 1. ä¿å­˜Mermaid PNGå›¾ç‰‡
            try:
                from IPython.display import Image
                from langchain_core.runnables.graph import MermaidDrawMethod
                
                png_data = self.graph.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)
                png_path = os.path.join(output_dir, f"langgraph_structure.png")
                
                with open(png_path, "wb") as f:
                    f.write(png_data)
                files_saved["mermaid_png"] = png_path
                print(f"âœ… Mermaid PNGå›¾ç‰‡å·²ä¿å­˜: {png_path}")
                
            except Exception as e:
                print(f"âš ï¸  ä¿å­˜Mermaid PNGå¤±è´¥: {e}")
                # å°è¯•ä¿å­˜Mermaidæºç 
                try:
                    mermaid_code = self.graph.get_graph().draw_mermaid()
                    mermaid_path = os.path.join(output_dir, f"langgraph_structure.mmd")
                    
                    with open(mermaid_path, "w", encoding="utf-8") as f:
                        f.write(mermaid_code)
                    files_saved["mermaid_code"] = mermaid_path
                    print(f"âœ… Mermaidæºç å·²ä¿å­˜: {mermaid_path}")
                    
                except Exception as e2:
                    print(f"âš ï¸  ä¿å­˜Mermaidæºç ä¹Ÿå¤±è´¥: {e2}")
            
            # 2. ä¿å­˜ASCIIç»“æ„
            try:
                ascii_structure = self.graph.get_graph().print_ascii()
                ascii_path = os.path.join(output_dir, f"langgraph_ascii.txt")
                
                with open(ascii_path, "w", encoding="utf-8") as f:
                    f.write(ascii_structure)
                files_saved["ascii_structure"] = ascii_path
                print(f"âœ… ASCIIç»“æ„å›¾å·²ä¿å­˜: {ascii_path}")
                
            except Exception as e:
                print(f"âš ï¸  ä¿å­˜ASCIIç»“æ„å¤±è´¥: {e}")
            
            # 3. ä¿å­˜è‡ªå®šä¹‰Mermaidå›¾ï¼ˆå¤‡ç”¨ï¼‰
            try:
                custom_mermaid = self.get_graph_visualization()
                custom_path = os.path.join(output_dir, f"langgraph_custom.mmd")
                
                with open(custom_path, "w", encoding="utf-8") as f:
                    f.write(custom_mermaid)
                files_saved["custom_mermaid"] = custom_path
                print(f"âœ… è‡ªå®šä¹‰Mermaidå›¾å·²ä¿å­˜: {custom_path}")
                
            except Exception as e:
                print(f"âš ï¸  ä¿å­˜è‡ªå®šä¹‰Mermaidå›¾å¤±è´¥: {e}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å›¾ç»“æ„æ—¶å‡ºç°é”™è¯¯: {e}")
        
        return files_saved
    
    def print_graph_structure(self):
        """
        æ‰“å°å›¾ç»“æ„ä¿¡æ¯
        """
        print("=" * 60)
        print("ğŸ” LangGraph ç»“æ„ä¿¡æ¯")
        print("=" * 60)
        
        try:
            # æ‰“å°ASCIIç»“æ„
            print("\nğŸ“Š ASCII ç»“æ„å›¾:")
            print("-" * 40)
            ascii_output = self.graph.get_graph().print_ascii()
            print(ascii_output)
            
        except Exception as e:
            print(f"âš ï¸  è·å–ASCIIç»“æ„å¤±è´¥: {e}")
        
        try:
            # æ‰“å°Mermaidä»£ç 
            print("\nğŸ¨ Mermaid å›¾å½¢ä»£ç :")
            print("-" * 40)
            mermaid_code = self.graph.get_graph().draw_mermaid()
            print(mermaid_code)
            
        except Exception as e:
            print(f"âš ï¸  è·å–Mermaidä»£ç å¤±è´¥: {e}")
        
        # æ‰“å°èŠ‚ç‚¹ä¿¡æ¯
        print("\nğŸ“‹ èŠ‚ç‚¹è¯¦ç»†ä¿¡æ¯:")
        print("-" * 40)
        nodes_info = [
            ("document_processor", "ğŸ“„ æ–‡æ¡£å¤„ç†å™¨", "åŠ è½½å’Œé¢„å¤„ç†Markdownæ–‡æ¡£"),
            ("document_analyzer", "ğŸ” æ–‡æ¡£åˆ†æå™¨", "æå–å…³é”®ç‚¹å’Œä¸»é¢˜"),
            ("generate_multiple_choice", "ğŸ“ é€‰æ‹©é¢˜ç”Ÿæˆå™¨", "ç”Ÿæˆå¤šé€‰é¢˜"),
            ("generate_fill_blank", "âœï¸ å¡«ç©ºé¢˜ç”Ÿæˆå™¨", "ç”Ÿæˆå¡«ç©ºé¢˜"),
            ("generate_matching", "ğŸ”— è¿çº¿é¢˜ç”Ÿæˆå™¨", "ç”ŸæˆåŒ¹é…é¢˜"),
            ("format_output", "ğŸ“Š è¾“å‡ºæ ¼å¼åŒ–å™¨", "æ ¼å¼åŒ–JSONè¾“å‡ºå’Œè´¨é‡éªŒè¯"),
            ("error_handler", "âš ï¸ é”™è¯¯å¤„ç†å™¨", "å¤„ç†å’Œè®°å½•é”™è¯¯")
        ]
        
        for node_id, name, desc in nodes_info:
            print(f"  â€¢ {name}: {desc}")
        
        print("\nğŸ”„ æ¡ä»¶åˆ†æ”¯:")
        print("-" * 40)
        conditions = [
            ("document_processor", "å¤„ç†æˆåŠŸ? â†’ æ–‡æ¡£åˆ†æå™¨ | é”™è¯¯å¤„ç†å™¨"),
            ("document_analyzer", "åˆ†ææˆåŠŸ? â†’ é€‰æ‹©é¢˜ç”Ÿæˆå™¨ | é”™è¯¯å¤„ç†å™¨"), 
            ("format_output", "æ ¼å¼åŒ–æˆåŠŸ? â†’ ç»“æŸ | é”™è¯¯å¤„ç†å™¨")
        ]
        
        for node, condition in conditions:
            print(f"  â€¢ {node}: {condition}")
        
        print("=" * 60) 