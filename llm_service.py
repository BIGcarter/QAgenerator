"""
LLMæœåŠ¡æ¨¡å— - å°è£…é€šä¹‰åƒé—®å’ŒOpenAIçš„è°ƒç”¨
"""
import os
import sys
import json
import logging
import warnings
from typing import Optional, Dict, Any, List

try:
    from langchain_core.language_models import BaseLanguageModel
except ImportError:
    try:
        from langchain.base_language import BaseLanguageModel
    except ImportError:
        from langchain.schema.language_model import BaseLanguageModel

from config import get_settings

# å–æ¶ˆwarningæ˜¾ç¤º
warnings.filterwarnings("ignore")

# è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºERROR
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)


class LLMService:
    """LLMæœåŠ¡ç±»ï¼Œæ”¯æŒé€šä¹‰åƒé—®å’ŒOpenAI"""
    
    def __init__(self):
        self.settings = get_settings()
        self._primary_llm = None
        self._backup_llm = None
        self._initialize_llms()
    
    def _initialize_llms(self):
        """åˆå§‹åŒ–LLMå®ä¾‹"""
        # æ£€æŸ¥å¹¶å°è¯•åˆå§‹åŒ–é€šä¹‰åƒé—®
        ali_api_key = self.settings.dashscope_api_key

        if ali_api_key and ali_api_key.strip():
            try:
                self._primary_llm = self._create_dashscope_llm()
                print("âœ… é€šä¹‰åƒé—®LLMåˆå§‹åŒ–æˆåŠŸ")
                # ä¸è¦ç›´æ¥returnï¼Œéœ€è¦æµ‹è¯•APIè¿æ¥
            except Exception as e:
                print(f"âš ï¸  é€šä¹‰åƒé—®åˆå§‹åŒ–å¤±è´¥: {e}")
        else:
            print("âš ï¸  æœªè®¾ç½®ALI_API_KEYç¯å¢ƒå˜é‡")
        
        # å°è¯•åˆå§‹åŒ–OpenAIä½œä¸ºå¤‡é€‰ï¼ˆåªæœ‰é€šä¹‰åƒé—®æ²¡æœ‰åˆå§‹åŒ–æˆåŠŸæ—¶æ‰å°è¯•ï¼‰
        if not self._primary_llm:
            openai_api_key = self.settings.openai_api_key  
            if openai_api_key and openai_api_key.strip():
                try:
                    self._backup_llm = self._create_openai_llm()
                    print("âœ… OpenAI LLMåˆå§‹åŒ–æˆåŠŸ(å¤‡é€‰æ–¹æ¡ˆ)")
                except Exception as e:
                    print(f"âš ï¸  OpenAIåˆå§‹åŒ–å¤±è´¥: {e}")
            else:
                print("âš ï¸  æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        
        if not self._primary_llm and not self._backup_llm:
            raise ValueError("âŒ æ— æ³•åˆå§‹åŒ–ä»»ä½•LLMï¼Œè¯·è®¾ç½®ALI_API_KEYæˆ–OPENAI_API_KEYç¯å¢ƒå˜é‡")
        
        # ğŸ” é‡è¦ï¼šæ€»æ˜¯æµ‹è¯•APIè¿æ¥
        self._test_api_connection()
    
    def _test_api_connection(self):
        """æµ‹è¯•APIè¿æ¥æ˜¯å¦æ­£å¸¸"""
        print("ğŸ” æµ‹è¯•APIè¿æ¥...")
        
        test_prompt = "æ»´æ»´æ»´ï¼Œè¯·é—®èƒ½æ”¶åˆ°æˆ‘è¿™è¾¹çš„ä¿¡æ¯å—ï¼Ÿæ”¶åˆ°çš„è¯è¯·å›å¤æ”¶åˆ°æ”¶åˆ°ã€‚"
        
        # æµ‹è¯•ä¸»LLM
        if self._primary_llm:
            try:
                print("   æµ‹è¯•é€šä¹‰åƒé—®è¿æ¥...")
                response = self._primary_llm.invoke(test_prompt)
                if response:
                    response_text = response if isinstance(response, str) else response.content
                    print("âœ… é€šä¹‰åƒé—®APIè¿æ¥æ­£å¸¸")
                    print(f"ğŸ“¤ å‘é€: {test_prompt}")
                    print(f"ğŸ“¥ å›å¤: {response_text}")
                    return  # ä¸»LLMå¯ç”¨ï¼Œæ— éœ€æµ‹è¯•å¤‡é€‰
                else:
                    print("âš ï¸  é€šä¹‰åƒé—®è¿”å›ç©ºå“åº”")
            except Exception as e:
                print(f"âŒ é€šä¹‰åƒé—®APIè¿æ¥å¤±è´¥: {e}")
                self._primary_llm = None  # æ ‡è®°ä¸ºä¸å¯ç”¨
        
        # å¦‚æœä¸»LLMå¤±è´¥ï¼Œæµ‹è¯•å¤‡é€‰LLM
        if self._backup_llm:
            try:
                print("   æµ‹è¯•OpenAIè¿æ¥...")
                response = self._backup_llm.invoke(test_prompt)
                if response:
                    response_text = response if isinstance(response, str) else response.content
                    print("âœ… OpenAI APIè¿æ¥æ­£å¸¸(å¤‡é€‰æ–¹æ¡ˆ)")
                    print(f"ğŸ“¤ å‘é€: {test_prompt}")
                    print(f"ğŸ“¥ å›å¤: {response_text}")
                    return
                else:
                    print("âš ï¸  OpenAIè¿”å›ç©ºå“åº”")
            except Exception as e:
                print(f"âŒ OpenAI APIè¿æ¥å¤±è´¥: {e}")
                self._backup_llm = None  # æ ‡è®°ä¸ºä¸å¯ç”¨
        
        # å¦‚æœæ‰€æœ‰APIéƒ½å¤±è´¥
        if not self._primary_llm and not self._backup_llm:
            print("\nâŒ æ‰€æœ‰APIè¿æ¥æµ‹è¯•å¤±è´¥ï¼")
            print("ğŸ“‹ å¯èƒ½çš„åŸå› ï¼š")
            print("   1. APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
            print("   2. ç½‘ç»œè¿æ¥é—®é¢˜")
            print("   3. APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
            print("\nğŸ’¡ è§£å†³å»ºè®®ï¼š")
            print("   1. æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
            print("   2. ç¡®è®¤APIå¯†é’¥æœ‰è¶³å¤Ÿæƒé™å’Œé¢åº¦")
            print("   3. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            raise ValueError("âŒ æ‰€æœ‰APIè¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥")
    
    def _create_dashscope_llm(self) -> BaseLanguageModel:
        """åˆ›å»ºé€šä¹‰åƒé—®LLMå®ä¾‹"""
        # ç›´æ¥ä½¿ç”¨ChatTongyiï¼Œç®€åŒ–å®ç°
        from langchain_community.chat_models.tongyi import ChatTongyi
        
        return ChatTongyi(
            dashscope_api_key=self.settings.dashscope_api_key,
            model_name=self.settings.default_model,
            temperature=self.settings.temperature,
            max_tokens=self.settings.max_tokens,
            streaming=False
        )
    

    
    def _create_openai_llm(self) -> BaseLanguageModel:
        """åˆ›å»ºOpenAI LLMå®ä¾‹"""
        try:
            # å°è¯•æ–°ç‰ˆæœ¬çš„å¯¼å…¥
            try:
                from langchain_openai import ChatOpenAI
            except ImportError:
                # å¤‡é€‰ï¼šæ—§ç‰ˆæœ¬çš„å¯¼å…¥
                try:
                    from langchain.chat_models import ChatOpenAI
                except ImportError:
                    from langchain.llms import OpenAI as ChatOpenAI
            
            return ChatOpenAI(
                openai_api_key=self.settings.openai_api_key,
                openai_api_base=self.settings.openai_base_url,
                model_name=self.settings.backup_model,
                temperature=self.settings.temperature,
                max_tokens=self.settings.max_tokens
            )
        except ImportError as e:
            logger.error(f"OpenAIæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            raise
    
    def get_llm(self, prefer_backup: bool = False) -> BaseLanguageModel:
        """è·å–LLMå®ä¾‹"""
        if prefer_backup and self._backup_llm:
            return self._backup_llm
        elif self._primary_llm:
            return self._primary_llm
        elif self._backup_llm:
            return self._backup_llm
        else:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„LLMå®ä¾‹")
    
    async def invoke_with_fallback(self, prompt: str, **kwargs) -> str:
        """å¸¦é™çº§çš„LLMè°ƒç”¨"""
        last_error = None
        
        # é¦–å…ˆå°è¯•ä¸»LLM
        if self._primary_llm:
            try:
                response = self._primary_llm.invoke(prompt)
                return response if isinstance(response, str) else response.content
            except Exception as e:
                last_error = e
                print(f"âš ï¸  é€šä¹‰åƒé—®è°ƒç”¨å¤±è´¥: {e}")
        
        # å¦‚æœä¸»LLMå¤±è´¥ï¼Œå°è¯•å¤‡é€‰LLM
        if self._backup_llm:
            try:
                response = self._backup_llm.invoke(prompt)
                return response if isinstance(response, str) else response.content
            except Exception as e:
                last_error = e
                print(f"âš ï¸  OpenAIè°ƒç”¨å¤±è´¥: {e}")
        
        error_msg = f"æ‰€æœ‰LLMéƒ½ä¸å¯ç”¨: {last_error}" if last_error else "æ²¡æœ‰å¯ç”¨çš„LLMå®ä¾‹"
        raise ValueError(error_msg)
    
    def parse_json_response(self, response: str) -> Dict[str, Any]:
        """è§£æLLMè¿”å›çš„JSONå“åº”"""
        try:
            # æå–JSONéƒ¨åˆ†
            if "```json" in response:
                start = response.find("```json") + 7
                end = response.find("```", start)
                json_str = response[start:end].strip()
            elif "```" in response:
                start = response.find("```") + 3
                end = response.find("```", start)
                json_str = response[start:end].strip()
            else:
                json_str = response.strip()
            
            # å°è¯•è§£æJSON
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
            logger.error(f"åŸå§‹å“åº”: {response}")
            raise ValueError(f"æ— æ³•è§£æLLMè¿”å›çš„JSON: {e}")


# å…¨å±€LLMæœåŠ¡å®ä¾‹
_llm_service = None


def get_llm_service() -> LLMService:
    """è·å–å…¨å±€LLMæœåŠ¡å®ä¾‹"""
    global _llm_service
    if _llm_service is None:
        _llm_service = LLMService()
    return _llm_service 